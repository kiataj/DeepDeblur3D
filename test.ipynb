{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf68af54-0e90-4e48-b02f-e56a1ccd1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (81, 712, 688) float32 min/max 0.000/1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RL (GPU) σ=3.82, iters=10:   0%|                                                                 | 0/1 [00:00<?, ?it/s]\n",
      "RL (GPU) iters:   0%|                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                                       \u001b[A\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_6be49\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6be49_level0_col0\" class=\"col_heading level0 col0\" >seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6be49_level0_row0\" class=\"row_heading level0 row0\" >USM (GPU)</th>\n",
       "      <td id=\"T_6be49_row0_col0\" class=\"data row0 col0\" >0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6be49_level0_row1\" class=\"row_heading level0 row1\" >LoG (GPU)</th>\n",
       "      <td id=\"T_6be49_row1_col0\" class=\"data row1 col0\" >0.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6be49_level0_row2\" class=\"row_heading level0 row2\" >Wiener (GPU)</th>\n",
       "      <td id=\"T_6be49_row2_col0\" class=\"data row2 col0\" >0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6be49_level0_row3\" class=\"row_heading level0 row3\" >RL (GPU)</th>\n",
       "      <td id=\"T_6be49_row3_col0\" class=\"data row3 col0\" >1.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6be49_level0_row4\" class=\"row_heading level0 row4\" >CNN α=2</th>\n",
       "      <td id=\"T_6be49_row4_col0\" class=\"data row4 col0\" >3.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6be49_level0_row5\" class=\"row_heading level0 row5\" >CNN (base)</th>\n",
       "      <td id=\"T_6be49_row5_col0\" class=\"data row5 col0\" >5.389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29d3916e710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "vol_path   = r\"U:\\users\\taki\\vizualization\\test.tif\"   # <-- set this\n",
    "ckpt_path  = \"deblur3d_unet.pt\"\n",
    "base, levels = 24, 4\n",
    "tile     = (64, 256, 256)\n",
    "overlap  = (32, 128, 128)\n",
    "spacing  = (1.0, 1.0, 1.0)\n",
    "\n",
    "# Baseline params (for 0–1 normalized data)\n",
    "FWHM_vox = 9.0\n",
    "sigma    = FWHM_vox / 2.3548\n",
    "USM_amount = 2\n",
    "LoG_lambda = 2\n",
    "Wiener_K   = 0.015\n",
    "RL_iters   = 10\n",
    "\n",
    "# ---- Controlled CNN presets (edit these) ----\n",
    "# strength: residual scaling (1.0 = as trained; <1 gentler; >1 stronger)\n",
    "# hp_sigma: high-pass Gaussian sigma (vox), hp_gain: multiply HP residual\n",
    "# lp_gain : mix-in of the low-pass (denoise) branch\n",
    "cnn_control_presets = [                                  # raw network (no control modulation)\n",
    "    (\"CNN α=2\",           dict(strength=2)),\n",
    "]\n",
    "\n",
    "# --- imports ---\n",
    "import os, time, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from deblur3d.data   import read_volume_float01\n",
    "from deblur3d.models import UNet3D_Residual, ControlledUNet3D\n",
    "from deblur3d.infer  import deblur_volume_tiled\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "assert device.type == \"cuda\", \"CUDA not available.\"\n",
    "\n",
    "# ---------- reusable kernels (GPU) ----------\n",
    "@torch.no_grad()\n",
    "def _gauss1d(sigma: float, device, dtype=torch.float32, radius_mult: float = 3.0):\n",
    "    import math\n",
    "    sigma = max(1e-6, float(sigma))\n",
    "    r = max(1, int(math.ceil(radius_mult * sigma)))\n",
    "    x = torch.arange(-r, r + 1, device=device, dtype=dtype)\n",
    "    k = torch.exp(-(x * x) / (2.0 * sigma * sigma))\n",
    "    return (k / (k.sum() + 1e-12)), r\n",
    "\n",
    "@torch.no_grad()\n",
    "def gaussian_blur3d_tensor(x: torch.Tensor, sigma: float, pad_mode=\"reflect\"):\n",
    "    if sigma <= 0: return x\n",
    "    k1d, r = _gauss1d(sigma, x.device, x.dtype)\n",
    "    kz = k1d.view(1,1,-1,1,1); ky = k1d.view(1,1,1,-1,1); kx = k1d.view(1,1,1,1,-1)\n",
    "    C = x.shape[1]\n",
    "    y = F.conv3d(F.pad(x, (0,0,0,0,r,r), mode=pad_mode), kz, groups=C)\n",
    "    y = F.conv3d(F.pad(y, (0,0,r,r,0,0), mode=pad_mode), ky, groups=C)\n",
    "    y = F.conv3d(F.pad(y, (r,r,0,0,0,0), mode=pad_mode), kx, groups=C)\n",
    "    return y\n",
    "\n",
    "@torch.no_grad()\n",
    "def laplacian3d_tensor(x: torch.Tensor, pad_mode=\"reflect\"):\n",
    "    w = torch.zeros((1,1,3,3,3), device=x.device, dtype=x.dtype)\n",
    "    w[0,0,1,1,1] = 6.0\n",
    "    w[0,0,1,1,0] = w[0,0,1,1,2] = -1.0\n",
    "    w[0,0,1,0,1] = w[0,0,1,2,1] = -1.0\n",
    "    w[0,0,0,1,1] = w[0,0,2,1,1] = -1.0\n",
    "    xpad = F.pad(x, (1,1,1,1,1,1), mode=pad_mode)\n",
    "    return F.conv3d(xpad, w)\n",
    "\n",
    "# ---------- GPU baselines ----------\n",
    "@torch.no_grad()\n",
    "def usm3d_gpu(vol_t: torch.Tensor, sigma, amount):\n",
    "    x = vol_t.unsqueeze(0).unsqueeze(0)\n",
    "    base = gaussian_blur3d_tensor(x, sigma)\n",
    "    y = (x + amount * (x - base)).clamp(0,1)\n",
    "    return y.squeeze().detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def log_sharpen3d_gpu(vol_t: torch.Tensor, sigma, lam):\n",
    "    x = vol_t.unsqueeze(0).unsqueeze(0)\n",
    "    g  = gaussian_blur3d_tensor(x, sigma)\n",
    "    L  = laplacian3d_tensor(g)\n",
    "    y  = (x - lam * L).clamp(0,1)\n",
    "    return y.squeeze().detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def wiener_gaussian3d_gpu(vol_t: torch.Tensor, sigma, K=0.01):\n",
    "    x = vol_t\n",
    "    D,H,W = x.shape\n",
    "    X = torch.fft.fftn(x)\n",
    "    fz = torch.fft.fftfreq(D, d=1.0, device=x.device).view(D,1,1)\n",
    "    fy = torch.fft.fftfreq(H, d=1.0, device=x.device).view(1,H,1)\n",
    "    fx = torch.fft.fftfreq(W, d=1.0, device=x.device).view(1,1,W)\n",
    "    two_pi2 = (2.0 * np.pi) ** 2\n",
    "    Htf = torch.exp(-0.5 * two_pi2 * (sigma**2) * (fz*fz + fy*fy + fx*fx))\n",
    "    Y = X * Htf / (Htf*Htf + K)\n",
    "    y = torch.fft.ifftn(Y).real.clamp(0,1)\n",
    "    return y.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def richardson_lucy3d_gpu(vol_t: torch.Tensor, sigma, n_iter=15):\n",
    "    x = vol_t.unsqueeze(0).unsqueeze(0)\n",
    "    psf1d, r = _gauss1d(sigma, x.device, x.dtype)\n",
    "    kz = psf1d.view(1,1,-1,1,1); ky = psf1d.view(1,1,1,-1,1); kx = psf1d.view(1,1,1,1,-1)\n",
    "    def psfZ(z): return F.conv3d(F.pad(z, (0,0,0,0,r,r), mode=\"replicate\"), kz)\n",
    "    def psfY(z): return F.conv3d(F.pad(z, (0,0,r,r,0,0), mode=\"replicate\"), ky)\n",
    "    def psfX(z): return F.conv3d(F.pad(z, (r,r,0,0,0,0), mode=\"replicate\"), kx)\n",
    "    def psf_conv(z):  return psfX(psfY(psfZ(z)))\n",
    "    y = x.clamp_min(1e-6)\n",
    "    it = tqdm(range(int(n_iter)), desc=\"RL (GPU) iters\", leave=False)\n",
    "    for _ in it:\n",
    "        est = psf_conv(y).clamp_min(1e-6)\n",
    "        ratio = x / est\n",
    "        y = (y * psf_conv(ratio)).clamp(0,1)\n",
    "    return y.squeeze().detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "# --- helper: accurate CUDA timing ---\n",
    "def run_timed_cuda(name, fn, *args, **kwargs):\n",
    "    torch.cuda.synchronize()\n",
    "    t0 = time.perf_counter()\n",
    "    with tqdm(total=1, desc=name, leave=False) as pbar:\n",
    "        out = fn(*args, **kwargs)\n",
    "        torch.cuda.synchronize()\n",
    "        dt = time.perf_counter() - t0\n",
    "        pbar.update(1)\n",
    "    return out, dt\n",
    "\n",
    "# --- load input volume & move to GPU once ---\n",
    "vol = read_volume_float01(vol_path)\n",
    "print(\"Input:\", vol.shape, vol.dtype, f\"min/max {vol.min():.3f}/{vol.max():.3f}\")\n",
    "vol_t = torch.from_numpy(vol).to(device, dtype=torch.float32)\n",
    "\n",
    "# --- load trained net + controller ---\n",
    "assert os.path.exists(ckpt_path), f\"Checkpoint not found: {ckpt_path}\"\n",
    "net = UNet3D_Residual(in_ch=1, base=base, levels=levels).to(device).eval()\n",
    "state = torch.load(ckpt_path, map_location=device)\n",
    "net.load_state_dict(state.get(\"state_dict\", state))\n",
    "ctrl = ControlledUNet3D(net).to(device).eval()   # controller wraps the trained net\n",
    "\n",
    "# small module to bind control kwargs so deblur_volume_tiled can call it like a net\n",
    "class NetWithControl(nn.Module):\n",
    "    def __init__(self, ctrl: ControlledUNet3D, **ctrl_kwargs):\n",
    "        super().__init__()\n",
    "        self.ctrl = ctrl\n",
    "        self.kw = ctrl_kwargs\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        return self.ctrl(x, **self.kw)\n",
    "\n",
    "times = {}\n",
    "cnn_results = []  # list of (name, np_array)\n",
    "\n",
    "# --- CNN base (no control) ---\n",
    "cnn_base, t_cnn_base = run_timed_cuda(\"CNN (base) tiled\", deblur_volume_tiled, net, vol, tile=tile, overlap=overlap, device=device.type)\n",
    "times[\"CNN (base)\"] = t_cnn_base\n",
    "cnn_results.append((\"CNN (base)\", cnn_base))\n",
    "\n",
    "# --- CNN controlled variants ---\n",
    "for name, kwargs in cnn_control_presets:\n",
    "    if name == \"CNN (base)\" and not kwargs:\n",
    "        continue  # already ran above\n",
    "    net_ctrl = NetWithControl(ctrl, **kwargs).to(device).eval()\n",
    "    out, dt = run_timed_cuda(f\"{name} tiled\", deblur_volume_tiled, net_ctrl, vol, tile=tile, overlap=overlap, device=device.type)\n",
    "    times[name] = dt\n",
    "    cnn_results.append((name, out))\n",
    "\n",
    "# --- baselines on GPU ---\n",
    "usm,  t_usm  = run_timed_cuda(f\"USM (GPU) σ={sigma:.2f}, a={USM_amount}\", usm3d_gpu, vol_t, sigma, USM_amount)\n",
    "logb, t_log  = run_timed_cuda(f\"LoG (GPU) σ={sigma:.2f}, λ={LoG_lambda}\",  log_sharpen3d_gpu, vol_t, sigma, LoG_lambda)\n",
    "wien, t_win  = run_timed_cuda(f\"Wiener (GPU) σ={sigma:.2f}, K={Wiener_K}\", wiener_gaussian3d_gpu, vol_t, sigma, Wiener_K)\n",
    "rl,   t_rl   = run_timed_cuda(f\"RL (GPU) σ={sigma:.2f}, iters={RL_iters}\", richardson_lucy3d_gpu, vol_t, sigma, RL_iters)\n",
    "\n",
    "times.update({\n",
    "    \"USM (GPU)\": t_usm,\n",
    "    \"LoG (GPU)\": t_log,\n",
    "    \"Wiener (GPU)\": t_win,\n",
    "    \"RL (GPU)\": t_rl,\n",
    "})\n",
    "\n",
    "# --- timing summary ---\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "    df_times = (\n",
    "        pd.DataFrame.from_dict(times, orient=\"index\", columns=[\"seconds\"])\n",
    "        .sort_values(\"seconds\")\n",
    "    )\n",
    "    display(df_times.style.format({\"seconds\": \"{:.3f}\"}))\n",
    "except Exception:\n",
    "    print(\"Times (s):\", {k: f\"{v:.3f}\" for k, v in times.items()})\n",
    "\n",
    "# --- visualize in napari ---\n",
    "import napari\n",
    "v = napari.Viewer(ndisplay=2)\n",
    "L_in  = v.add_image(vol,  name=\"Input\",      colormap=\"gray\", scale=spacing)\n",
    "\n",
    "# add all CNN variants first\n",
    "for name, arr in cnn_results:\n",
    "    L = v.add_image(arr, name=name, colormap=\"gray\", scale=spacing, opacity=0.85)\n",
    "    L.contrast_limits = L_in.contrast_limits\n",
    "\n",
    "# add baselines\n",
    "L_usm = v.add_image(usm,  name=f\"USM σ={sigma:.2f} a={USM_amount}\",  colormap=\"gray\", scale=spacing, opacity=0.85)\n",
    "L_log = v.add_image(logb, name=f\"LoG σ={sigma:.2f} λ={LoG_lambda}\",  colormap=\"gray\", scale=spacing, opacity=0.85)\n",
    "L_win = v.add_image(wien, name=f\"Wiener σ={sigma:.2f} K={Wiener_K}\", colormap=\"gray\", scale=spacing, opacity=0.85)\n",
    "L_rl  = v.add_image(rl,   name=f\"RL σ={sigma:.2f} iters={RL_iters}\", colormap=\"gray\", scale=spacing, opacity=0.85)\n",
    "\n",
    "for L in (L_usm, L_log, L_win, L_rl):\n",
    "    L.contrast_limits = L_in.contrast_limits\n",
    "\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a6d4c2-30b1-4e91-81e3-daa6d378f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Micro-CT metrics with input-anchored noise =====\n",
    "import torch, numpy as np, pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def _to_t(x): return torch.from_numpy(x).to(device=device, dtype=torch.float32)\n",
    "\n",
    "def _center_crop_np(x, maxD=128, maxH=256, maxW=256):\n",
    "    D,H,W = x.shape\n",
    "    d = min(D, maxD); h = min(H, maxH); w = min(W, maxW)\n",
    "    zs = (D - d)//2; ys = (H - h)//2; xs = (W - w)//2\n",
    "    return x[zs:zs+d, ys:ys+h, xs:xs+w].copy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def _tenengrad_3d(x: torch.Tensor):\n",
    "    k = torch.tensor([1, 2, 1], dtype=x.dtype, device=x.device)\n",
    "    d = torch.tensor([1, 0,-1], dtype=x.dtype, device=x.device)\n",
    "    kz = d.view(1,1,3,1,1); ky = d.view(1,1,1,3,1); kx = d.view(1,1,1,1,3)\n",
    "    x4 = x.unsqueeze(0).unsqueeze(0)\n",
    "    gz = F.conv3d(F.pad(x4,(0,0,0,0,1,1),'replicate'), kz)\n",
    "    gy = F.conv3d(F.pad(x4,(0,0,1,1,0,0),'replicate'), ky)\n",
    "    gx = F.conv3d(F.pad(x4,(1,1,0,0,0,0),'replicate'), kx)\n",
    "    return (gx*gx + gy*gy + gz*gz).mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def _lap_var_3d(x: torch.Tensor):\n",
    "    w = torch.zeros((1,1,3,3,3), device=x.device, dtype=x.dtype)\n",
    "    w[0,0,1,1,1] = 6.0\n",
    "    w[0,0,1,1,0] = w[0,0,1,1,2] = -1.0\n",
    "    w[0,0,1,0,1] = w[0,0,1,2,1] = -1.0\n",
    "    w[0,0,0,1,1] = w[0,0,2,1,1] = -1.0\n",
    "    y = F.conv3d(F.pad(x.unsqueeze(0).unsqueeze(0),(1,1,1,1,1,1),'replicate'), w).squeeze()\n",
    "    return y.var().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def _gauss_separable(x4, sigma):\n",
    "    # x4: (1,1,D,H,W)\n",
    "    import math\n",
    "    s = max(1e-6, float(sigma))\n",
    "    r = max(1, int(math.ceil(3*s)))\n",
    "    z = torch.arange(-r, r+1, device=x4.device, dtype=x4.dtype)\n",
    "    g = torch.exp(-(z*z)/(2*s*s)); g = g/g.sum()\n",
    "    kz = g.view(1,1,-1,1,1); ky = g.view(1,1,1,-1,1); kx = g.view(1,1,1,1,-1)\n",
    "    y = F.conv3d(F.pad(x4,(0,0,0,0,r,r),'reflect'), kz)\n",
    "    y = F.conv3d(F.pad(y,(0,0,r,r,0,0),'reflect'), ky)\n",
    "    y = F.conv3d(F.pad(y,(r,r,0,0,0,0),'reflect'), kx)\n",
    "    return y\n",
    "\n",
    "@torch.no_grad()\n",
    "def _build_flat_mask_from_input(x_in: torch.Tensor, flat_pct=0.30, min_vox=32768):\n",
    "    \"\"\"Select low-texture voxels from the *input*; same mask reused for all methods.\"\"\"\n",
    "    t = x_in.unsqueeze(0).unsqueeze(0)\n",
    "    # light pre-blur to suppress texture edges influencing the mask\n",
    "    t_s = _gauss_separable(t, sigma=0.7)\n",
    "    k = torch.tensor([1,0,-1], dtype=t.dtype, device=t.device).view(1,1,3,1,1)\n",
    "    gx = F.conv3d(F.pad(t_s,(0,0,0,0,1,1),'replicate'), k).abs()\n",
    "    gy = F.conv3d(F.pad(t_s,(0,0,1,1,0,0),'replicate'), k.transpose(2,3)).abs()\n",
    "    gz = F.conv3d(F.pad(t_s,(1,1,0,0,0,0),'replicate'),\n",
    "                  torch.tensor([1,0,-1], dtype=t.dtype, device=t.device).view(1,1,1,1,3)).abs()\n",
    "    grad = (gx + gy + gz).squeeze()\n",
    "    q = torch.quantile(grad, flat_pct, interpolation=\"nearest\")\n",
    "    m = (grad <= q)\n",
    "    if m.sum().item() < min_vox:  # ensure enough samples\n",
    "        ksel = min(min_vox, grad.numel())\n",
    "        _, idx = torch.topk((-grad).flatten(), k=ksel)  # smallest gradients\n",
    "        m = torch.zeros_like(grad, dtype=torch.bool).flatten()\n",
    "        m[idx] = True\n",
    "        m = m.view_as(grad)\n",
    "    return m  # bool (D,H,W)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _noise_mad_hp_masked(x: torch.Tensor, mask: torch.Tensor, sigma=1.0):\n",
    "    \"\"\"MAD of high-pass residual over a fixed mask.\"\"\"\n",
    "    x4 = x.unsqueeze(0).unsqueeze(0)\n",
    "    low = _gauss_separable(x4, sigma=sigma).squeeze()\n",
    "    hp = (x - low)\n",
    "    r = hp[mask]\n",
    "    if r.numel() == 0:\n",
    "        return float('nan')\n",
    "    med = r.median()\n",
    "    mad = (r - med).abs().median() * 1.4826\n",
    "    # avoid printing 0.0000 due to float underflow in display\n",
    "    return float(mad.item() + 1e-12)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _hf_energy_ratio(x: torch.Tensor, r0=0.6):\n",
    "    D,H,W = x.shape\n",
    "    X = torch.fft.fftn(x); P = (X.abs()**2)\n",
    "    fz = torch.fft.fftfreq(D, d=1.0, device=x.device).view(D,1,1)\n",
    "    fy = torch.fft.fftfreq(H, d=1.0, device=x.device).view(1,H,1)\n",
    "    fx = torch.fft.fftfreq(W, d=1.0, device=x.device).view(1,1,W)\n",
    "    fny = 0.5\n",
    "    r = torch.sqrt((fz/fny)**2 + (fy/fny)**2 + (fx/fny)**2)\n",
    "    mask = (r >= r0)\n",
    "    return (P[mask].sum() / (P.sum() + 1e-12)).item()\n",
    "\n",
    "def evaluate_methods_no_gt(\n",
    "    outputs: dict,\n",
    "    vol_input: np.ndarray,\n",
    "    crop=(128,256,256),\n",
    "    hp_sigma_noise=1.0,\n",
    "    flat_pct=0.30,\n",
    "    min_vox=32768,\n",
    "    hf_r0=0.6,\n",
    "):\n",
    "    \"\"\"\n",
    "    outputs: dict name -> np.ndarray (D,H,W) in [0,1], should include 'Input'\n",
    "    vol_input: original input volume (np.ndarray) used to anchor the flat mask\n",
    "    crop: center crop size for metrics (reduces FFT memory)\n",
    "    hp_sigma_noise: sigma (vox) for LP in high-pass residual for Noise_MAD\n",
    "    flat_pct: fraction of lowest-gradient voxels (on input) to define 'flat' mask\n",
    "    min_vox: minimum voxels guaranteed in the flat mask\n",
    "    hf_r0: normalized radius threshold for HF energy ratio (0..1 of Nyquist)\n",
    "    \"\"\"\n",
    "    # center crop input and move to device\n",
    "    xin_c = _center_crop_np(vol_input, *crop)\n",
    "    x_in  = _to_t(xin_c)\n",
    "\n",
    "    # build a fixed 'flat' mask from INPUT (reused across methods)\n",
    "    flat_mask = _build_flat_mask_from_input(x_in, flat_pct=flat_pct, min_vox=min_vox)\n",
    "\n",
    "    # input's own noise for NRF\n",
    "    noise_in = _noise_mad_hp_masked(x_in, flat_mask, sigma=hp_sigma_noise)\n",
    "\n",
    "    rows = []\n",
    "    hf_col = f\"HF_ratio@r>{hf_r0}\"\n",
    "    for name, arr in outputs.items():\n",
    "        arr_c = _center_crop_np(arr, *crop)\n",
    "        y = _to_t(arr_c)\n",
    "\n",
    "        row = {\"method\": name}\n",
    "        row[\"Tenengrad\"] = _tenengrad_3d(y)\n",
    "        row[\"Var(Lap)\"]  = _lap_var_3d(y)\n",
    "        # HF energy ratio at radius hf_r0\n",
    "        row[hf_col]      = _hf_energy_ratio(y, r0=hf_r0)\n",
    "\n",
    "        # input-anchored noise + NRF\n",
    "        noise = _noise_mad_hp_masked(y, flat_mask, sigma=hp_sigma_noise)\n",
    "        row[\"Noise_MAD\"] = noise\n",
    "        row[\"NRF\"]       = float(noise / (noise_in + 1e-12))  # <1 = denoised vs input\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(rows).set_index(\"method\")\n",
    "\n",
    "    # join runtimes (map common baseline keys; CNN variants usually already match)\n",
    "    if \"times\" in globals() and isinstance(times, dict):\n",
    "        alias = {\n",
    "            \"USM (GPU)\": \"USM\",\n",
    "            \"LoG (GPU)\": \"LoG\",\n",
    "            \"Wiener (GPU)\": \"Wiener\",\n",
    "            \"RL (GPU)\": \"RL\",\n",
    "            \"CNN (base)\": \"CNN (base)\",\n",
    "        }\n",
    "        t = pd.Series({alias.get(k, k): v for k, v in times.items()}, name=\"seconds\")\n",
    "        df = df.join(t, how=\"left\")\n",
    "\n",
    "    # order columns\n",
    "    cols = [c for c in [\"Tenengrad\",\"Var(Lap)\", hf_col, \"Noise_MAD\",\"NRF\",\"seconds\"] if c in df.columns]\n",
    "    df = df[cols]\n",
    "\n",
    "    # sort: sharpness ↑ then NRF ↓ (if present)\n",
    "    sort_keys, asc = [], []\n",
    "    if \"Tenengrad\" in df.columns: sort_keys.append(\"Tenengrad\"); asc.append(False)\n",
    "    if \"NRF\" in df.columns:       sort_keys.append(\"NRF\");       asc.append(True)\n",
    "    if sort_keys:\n",
    "        df = df.sort_values(by=sort_keys, ascending=asc)\n",
    "\n",
    "    return df\n",
    "\n",
    "# ==== Automatic CNR metric (no manual ROIs) ====\n",
    "\n",
    "@torch.no_grad()\n",
    "def _otsu_threshold_from_masked(x: torch.Tensor, mask: torch.Tensor, bins=256):\n",
    "    \"\"\"Otsu threshold on x[mask] in [0,1]. Returns float threshold (CPU scalar).\"\"\"\n",
    "    vals = x[mask].clamp(0,1).detach().float().cpu().numpy()\n",
    "    if vals.size < 1024:  # too few voxels -> fallback to mid\n",
    "        return float(vals.mean())\n",
    "    hist, edges = np.histogram(vals, bins=bins, range=(0.0,1.0))\n",
    "    hist = hist.astype(np.float64); w = hist.sum()\n",
    "    if w <= 0: return 0.5\n",
    "    p = hist / w\n",
    "    omega = np.cumsum(p)\n",
    "    mu = np.cumsum(p * (edges[:-1] + edges[1:]) * 0.5)\n",
    "    mu_t = mu[-1]\n",
    "    sigma_b = (mu_t * omega - mu)**2 / (omega * (1.0 - omega) + 1e-12)\n",
    "    k = np.nanargmax(sigma_b)\n",
    "    # threshold at bin boundary\n",
    "    return float((edges[k] + edges[k+1]) * 0.5)\n",
    "\n",
    "@torch.no_grad()\n",
    "def _robust_sigma(v: torch.Tensor):\n",
    "    \"\"\"Robust σ via MAD (Gaussian equiv). v is 1D tensor.\"\"\"\n",
    "    if v.numel() == 0: return torch.tensor(float('nan'), device=v.device)\n",
    "    med = v.median()\n",
    "    mad = (v - med).abs().median()\n",
    "    return mad * 1.4826\n",
    "\n",
    "@torch.no_grad()\n",
    "def _auto_cnr_on_fixed_partition(out_y: torch.Tensor,\n",
    "                                 x_in: torch.Tensor,\n",
    "                                 flat_mask: torch.Tensor,\n",
    "                                 thr: float,\n",
    "                                 robust=True,\n",
    "                                 min_class_vox=4096):\n",
    "    \"\"\"\n",
    "    Compute CNR on two classes defined ON INPUT (x_in <= thr and > thr), restricted to flat_mask.\n",
    "    Returns (cnr, mu0, mu1, sig0, sig1, n0, n1).\n",
    "    \"\"\"\n",
    "    m0 = flat_mask & (x_in <= thr)\n",
    "    m1 = flat_mask & (x_in >  thr)\n",
    "    # ensure both classes have some voxels; fallback to quantile split on input if needed\n",
    "    if m0.sum().item() < min_class_vox or m1.sum().item() < min_class_vox:\n",
    "        q0, q1 = torch.quantile(x_in[flat_mask], torch.tensor([0.3, 0.7], device=x_in.device))\n",
    "        m0 = flat_mask & (x_in <= q0)\n",
    "        m1 = flat_mask & (x_in >= q1)\n",
    "\n",
    "    v0 = out_y[m0]; v1 = out_y[m1]\n",
    "    if robust:\n",
    "        s0 = _robust_sigma(v0); s1 = _robust_sigma(v1)\n",
    "    else:\n",
    "        s0 = v0.std(unbiased=False); s1 = v1.std(unbiased=False)\n",
    "    mu0 = v0.mean(); mu1 = v1.mean()\n",
    "    cnr = (mu1 - mu0).abs() / torch.sqrt(s0*s0 + s1*s1 + 1e-12)\n",
    "    return float(cnr.item()), float(mu0.item()), float(mu1.item()), float(s0.item()), float(s1.item()), int(v0.numel()), int(v1.numel())\n",
    "\n",
    "def add_auto_cnr_columns(df: pd.DataFrame,\n",
    "                         outputs: dict,\n",
    "                         vol_input: np.ndarray,\n",
    "                         vx_size: float,\n",
    "                         crop=(128,256,256),\n",
    "                         hp_sigma_noise=1.0,  # reuse your noise LP sigma\n",
    "                         flat_pct=0.30,\n",
    "                         min_vox=32768,\n",
    "                         robust=True):\n",
    "    \"\"\"\n",
    "    Appends 'aCNR' and 'aCNR/(2.4*vx)' columns using:\n",
    "      - flat mask from input (low-gradient voxels)\n",
    "      - Otsu threshold computed ON INPUT within that mask\n",
    "      - same spatial voxels used for every method\n",
    "    \"\"\"\n",
    "    # center crop input and move to device\n",
    "    xin_c = _center_crop_np(vol_input, *crop)\n",
    "    x_in  = _to_t(xin_c)\n",
    "\n",
    "    # fixed flat mask from input\n",
    "    flat_mask = _build_flat_mask_from_input(x_in, flat_pct=flat_pct, min_vox=min_vox)\n",
    "\n",
    "    # threshold from input (masked Otsu)\n",
    "    thr = _otsu_threshold_from_masked(x_in, flat_mask, bins=256)\n",
    "\n",
    "    # compute aCNR per method\n",
    "    acnr, acnr_norm = {}, {}\n",
    "    for name, arr in outputs.items():\n",
    "        arr_c = _center_crop_np(arr, *crop)\n",
    "        y = _to_t(arr_c)\n",
    "        cnr, *_ = _auto_cnr_on_fixed_partition(y, x_in, flat_mask, thr, robust=robust)\n",
    "        acnr[name]      = cnr\n",
    "        acnr_norm[name] = cnr / (2.4 * float(vx_size) + 1e-12)\n",
    "\n",
    "    df[\"aCNR\"] = pd.Series(acnr)\n",
    "    df[f\"aCNR/(2.4*vx)\"] = pd.Series(acnr_norm)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd1c0edd-afdf-4e42-b03e-1bef92430218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_13d91\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_13d91_level0_col0\" class=\"col_heading level0 col0\" >Tenengrad</th>\n",
       "      <th id=\"T_13d91_level0_col1\" class=\"col_heading level0 col1\" >Var(Lap)</th>\n",
       "      <th id=\"T_13d91_level0_col2\" class=\"col_heading level0 col2\" >HF_ratio@r>0.6</th>\n",
       "      <th id=\"T_13d91_level0_col3\" class=\"col_heading level0 col3\" >Noise_MAD</th>\n",
       "      <th id=\"T_13d91_level0_col4\" class=\"col_heading level0 col4\" >NRF</th>\n",
       "      <th id=\"T_13d91_level0_col5\" class=\"col_heading level0 col5\" >seconds</th>\n",
       "      <th id=\"T_13d91_level0_col6\" class=\"col_heading level0 col6\" >aCNR</th>\n",
       "      <th id=\"T_13d91_level0_col7\" class=\"col_heading level0 col7\" >aCNR/(2.4*vx)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >method</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row0\" class=\"row_heading level0 row0\" >USM</th>\n",
       "      <td id=\"T_13d91_row0_col0\" class=\"data row0 col0\" >3.5922e-02</td>\n",
       "      <td id=\"T_13d91_row0_col1\" class=\"data row0 col1\" >3.7292e-02</td>\n",
       "      <td id=\"T_13d91_row0_col2\" class=\"data row0 col2\" >0.0044</td>\n",
       "      <td id=\"T_13d91_row0_col3\" class=\"data row0 col3\" >0.04058</td>\n",
       "      <td id=\"T_13d91_row0_col4\" class=\"data row0 col4\" >2.971</td>\n",
       "      <td id=\"T_13d91_row0_col5\" class=\"data row0 col5\" >0.221</td>\n",
       "      <td id=\"T_13d91_row0_col6\" class=\"data row0 col6\" >1.980</td>\n",
       "      <td id=\"T_13d91_row0_col7\" class=\"data row0 col7\" >0.8248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row1\" class=\"row_heading level0 row1\" >CNN α=2</th>\n",
       "      <td id=\"T_13d91_row1_col0\" class=\"data row1 col0\" >1.9414e-02</td>\n",
       "      <td id=\"T_13d91_row1_col1\" class=\"data row1 col1\" >9.9185e-03</td>\n",
       "      <td id=\"T_13d91_row1_col2\" class=\"data row1 col2\" >0.0039</td>\n",
       "      <td id=\"T_13d91_row1_col3\" class=\"data row1 col3\" >0.01543</td>\n",
       "      <td id=\"T_13d91_row1_col4\" class=\"data row1 col4\" >1.130</td>\n",
       "      <td id=\"T_13d91_row1_col5\" class=\"data row1 col5\" >3.612</td>\n",
       "      <td id=\"T_13d91_row1_col6\" class=\"data row1 col6\" >2.294</td>\n",
       "      <td id=\"T_13d91_row1_col7\" class=\"data row1 col7\" >0.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row2\" class=\"row_heading level0 row2\" >Wiener</th>\n",
       "      <td id=\"T_13d91_row2_col0\" class=\"data row2 col0\" >1.4820e-02</td>\n",
       "      <td id=\"T_13d91_row2_col1\" class=\"data row2 col1\" >1.5777e-03</td>\n",
       "      <td id=\"T_13d91_row2_col2\" class=\"data row2 col2\" >0.0003</td>\n",
       "      <td id=\"T_13d91_row2_col3\" class=\"data row2 col3\" >0.00940</td>\n",
       "      <td id=\"T_13d91_row2_col4\" class=\"data row2 col4\" >0.688</td>\n",
       "      <td id=\"T_13d91_row2_col5\" class=\"data row2 col5\" >0.477</td>\n",
       "      <td id=\"T_13d91_row2_col6\" class=\"data row2 col6\" >1.980</td>\n",
       "      <td id=\"T_13d91_row2_col7\" class=\"data row2 col7\" >0.8251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row3\" class=\"row_heading level0 row3\" >CNN (base)</th>\n",
       "      <td id=\"T_13d91_row3_col0\" class=\"data row3 col0\" >1.3935e-02</td>\n",
       "      <td id=\"T_13d91_row3_col1\" class=\"data row3 col1\" >8.6867e-03</td>\n",
       "      <td id=\"T_13d91_row3_col2\" class=\"data row3 col2\" >0.0040</td>\n",
       "      <td id=\"T_13d91_row3_col3\" class=\"data row3 col3\" >0.01205</td>\n",
       "      <td id=\"T_13d91_row3_col4\" class=\"data row3 col4\" >0.882</td>\n",
       "      <td id=\"T_13d91_row3_col5\" class=\"data row3 col5\" >5.389</td>\n",
       "      <td id=\"T_13d91_row3_col6\" class=\"data row3 col6\" >2.528</td>\n",
       "      <td id=\"T_13d91_row3_col7\" class=\"data row3 col7\" >1.0532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row4\" class=\"row_heading level0 row4\" >RL</th>\n",
       "      <td id=\"T_13d91_row4_col0\" class=\"data row4 col0\" >9.7358e-03</td>\n",
       "      <td id=\"T_13d91_row4_col1\" class=\"data row4 col1\" >4.3880e-03</td>\n",
       "      <td id=\"T_13d91_row4_col2\" class=\"data row4 col2\" >0.0008</td>\n",
       "      <td id=\"T_13d91_row4_col3\" class=\"data row4 col3\" >0.01423</td>\n",
       "      <td id=\"T_13d91_row4_col4\" class=\"data row4 col4\" >1.042</td>\n",
       "      <td id=\"T_13d91_row4_col5\" class=\"data row4 col5\" >1.014</td>\n",
       "      <td id=\"T_13d91_row4_col6\" class=\"data row4 col6\" >2.316</td>\n",
       "      <td id=\"T_13d91_row4_col7\" class=\"data row4 col7\" >0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row5\" class=\"row_heading level0 row5\" >Input</th>\n",
       "      <td id=\"T_13d91_row5_col0\" class=\"data row5 col0\" >5.6434e-03</td>\n",
       "      <td id=\"T_13d91_row5_col1\" class=\"data row5 col1\" >4.4227e-03</td>\n",
       "      <td id=\"T_13d91_row5_col2\" class=\"data row5 col2\" >0.0008</td>\n",
       "      <td id=\"T_13d91_row5_col3\" class=\"data row5 col3\" >0.01366</td>\n",
       "      <td id=\"T_13d91_row5_col4\" class=\"data row5 col4\" >1.000</td>\n",
       "      <td id=\"T_13d91_row5_col5\" class=\"data row5 col5\" >nan</td>\n",
       "      <td id=\"T_13d91_row5_col6\" class=\"data row5 col6\" >2.431</td>\n",
       "      <td id=\"T_13d91_row5_col7\" class=\"data row5 col7\" >1.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_13d91_level0_row6\" class=\"row_heading level0 row6\" >LoG</th>\n",
       "      <td id=\"T_13d91_row6_col0\" class=\"data row6 col0\" >5.3420e-03</td>\n",
       "      <td id=\"T_13d91_row6_col1\" class=\"data row6 col1\" >4.4068e-03</td>\n",
       "      <td id=\"T_13d91_row6_col2\" class=\"data row6 col2\" >0.0008</td>\n",
       "      <td id=\"T_13d91_row6_col3\" class=\"data row6 col3\" >0.01360</td>\n",
       "      <td id=\"T_13d91_row6_col4\" class=\"data row6 col4\" >0.996</td>\n",
       "      <td id=\"T_13d91_row6_col5\" class=\"data row6 col5\" >0.226</td>\n",
       "      <td id=\"T_13d91_row6_col6\" class=\"data row6 col6\" >2.400</td>\n",
       "      <td id=\"T_13d91_row6_col7\" class=\"data row6 col7\" >1.0002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x29f96092590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vx_size: voxel edge length in your chosen units (e.g., micrometers); if anisotropic, pass the in-plane or mean.\n",
    "vx_size = 1.0  # <-- set (e.g., µm per voxel). If your spacing is (z,y,x), you can use np.mean(spacing).\n",
    "\n",
    "outputs = {\"Input\": vol, \"USM\": usm, \"LoG\": logb, \"Wiener\": wien, \"RL\": rl}\n",
    "for name, arr in cnn_results:  # e.g. (\"CNN (base)\", ...), (\"CNN α=2\", ...), ...\n",
    "    outputs[name] = arr\n",
    "    \n",
    "df_metrics = evaluate_methods_no_gt(\n",
    "    outputs, vol_input=vol,\n",
    "    crop=(128,256,256),\n",
    "    hp_sigma_noise=1.0,  # noise LP sigma (vox)\n",
    "    flat_pct=0.30,       # lowest-gradient fraction for mask\n",
    "    min_vox=32768,       # ensure stable MAD\n",
    "    hf_r0=0.6            # HF radius threshold (fraction of Nyquist)\n",
    ")\n",
    "\n",
    "df_metrics = add_auto_cnr_columns(\n",
    "    df_metrics, outputs, vol_input=vol,\n",
    "    vx_size=vx_size,\n",
    "    crop=(128,256,256),\n",
    "    hp_sigma_noise=1.0,\n",
    "    flat_pct=0.30, min_vox=32768,\n",
    "    robust=True\n",
    ")\n",
    "\n",
    "# Pretty print (adds new cols if present)\n",
    "fmt_extra = {\"aCNR\":\"{:.3f}\", \"aCNR/(2.4*vx)\":\"{:.4f}\"}\n",
    "fmt_all = {\n",
    "    \"Tenengrad\":\"{:.4e}\", \"Var(Lap)\":\"{:.4e}\",\n",
    "    \"HF_ratio@r>0.6\":\"{:.4f}\", \"Noise_MAD\":\"{:.5f}\", \"NRF\":\"{:.3f}\",\n",
    "    \"seconds\":\"{:.3f}\", **fmt_extra\n",
    "}\n",
    "display(df_metrics.style.format({k:v for k,v in fmt_all.items() if k in df_metrics.columns}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b610d7-f818-41e7-b33a-b07d7910e7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deblur3d)",
   "language": "python",
   "name": "deblur3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
