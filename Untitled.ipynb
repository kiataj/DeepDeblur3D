{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b34291-e09a-4931-b95e-f0cf21baefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- MLflow setup ----------\n",
    "EXPERIMENT_NAME = \"deblur3d_microCT\"\n",
    "RUN_NAME        = \"unet3d_residual_base24L4\"   # change per run\n",
    "TRACKING_URI    = None  # e.g. \"http://your-mlflow:5000\" or None for local ./mlruns\n",
    "\n",
    "if TRACKING_URI:\n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "# ---------- Log static params ----------\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"model\": type(net).__name__,\n",
    "    \"in_ch\": 1, \"base\": 24, \"levels\": 4,          # keep in sync with your model init\n",
    "    \"optimizer\": \"AdamW\", \"lr\": 2e-4, \"weight_decay\": 1e-4, \"betas\": (0.9, 0.99),\n",
    "    \"scheduler\": \"CosineAnnealingLR\", \"epochs\": 50,\n",
    "    \"amp\": bool(use_amp), \"device\": str(device),\n",
    "}\n",
    "data_params = {\n",
    "    \"patch_size\": tuple(loader_train.dataset.patch_size) if hasattr(loader_train.dataset, \"patch_size\") else None,\n",
    "    \"batch_size\": loader_train.batch_size,\n",
    "    \"num_workers\": loader_train.num_workers,\n",
    "    \"train_volumes\": len(getattr(loader_train.dataset, \"vols\", getattr(loader_train.dataset, \"paths\", []))),\n",
    "    \"val_exists\": loader_val is not None,\n",
    "}\n",
    "loss_params = {\n",
    "    \"loss\": type(criterion).__name__,\n",
    "    **{k:getattr(criterion,k) for k in (\"w_l1\",\"w_ssim\",\"w_freq\",\"idw\") if hasattr(criterion,k)},\n",
    "}\n",
    "\n",
    "# ---------- Training loop with MLflow ----------\n",
    "with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(\"MLflow run_id:\", run_id)\n",
    "\n",
    "    # log params once\n",
    "    mlflow.log_params(model_params)\n",
    "    mlflow.log_params(data_params)\n",
    "    mlflow.log_params(loss_params)\n",
    "\n",
    "    # environment snapshot\n",
    "    env = {\n",
    "        \"python\": platform.python_version(),\n",
    "        \"torch\": torch.__version__,\n",
    "        \"cuda_available\": torch.cuda.is_available(),\n",
    "        \"cuda_device\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else None,\n",
    "    }\n",
    "    mlflow.log_dict(env, \"env.json\")\n",
    "    req_path = _freeze_requirements()\n",
    "    if req_path:\n",
    "        mlflow.log_artifact(req_path, artifact_path=\"env\")\n",
    "\n",
    "    best_psnr = -1.0\n",
    "    best_path = \"deblur3d_unet.pt\"\n",
    "\n",
    "    def to_ch(x): return x.unsqueeze(1)  # (B,1,D,H,W)\n",
    "\n",
    "    for epoch in range(1, 51):\n",
    "        net.train()\n",
    "        t0 = time.time()\n",
    "        tr_loss = 0.0\n",
    "        nvox = 0\n",
    "\n",
    "        for sharp, blurred in loader_train:\n",
    "            sharp   = to_ch(sharp).to(device, non_blocking=True)\n",
    "            blurred = to_ch(blurred).to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                pred = net(blurred)\n",
    "                loss = criterion(pred, sharp, blurred)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "            scaler.step(opt); scaler.update()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            bs = sharp.size(0)\n",
    "            tr_loss += loss.item() * bs\n",
    "            nvox    += bs\n",
    "\n",
    "        sched.step()\n",
    "        epoch_time = time.time() - t0\n",
    "        train_loss_epoch = tr_loss / max(nvox, 1)\n",
    "\n",
    "        # validation (PSNR)\n",
    "        net.eval(); psnr_sum, nvox = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for sharp, blurred in (loader_val or []):  # handle None\n",
    "                sharp   = to_ch(sharp).to(device, non_blocking=True)\n",
    "                blurred = to_ch(blurred).to(device, non_blocking=True)\n",
    "                pred = net(blurred)\n",
    "                mse  = F.mse_loss(pred, sharp, reduction='none').mean(dim=(1,2,3,4))\n",
    "                psnr = 10 * torch.log10(1.0 / (mse + 1e-12))\n",
    "                psnr_sum += psnr.sum().item()\n",
    "                nvox += sharp.size(0)\n",
    "        psnr_epoch = (psnr_sum / nvox) if nvox > 0 else float(\"nan\")\n",
    "\n",
    "        # --- log metrics ---\n",
    "        mlflow.log_metric(\"train/loss\", train_loss_epoch, step=epoch)\n",
    "        mlflow.log_metric(\"time/epoch_sec\", epoch_time, step=epoch)\n",
    "        if not (psnr_epoch != psnr_epoch):  # NaN check\n",
    "            mlflow.log_metric(\"val/PSNR_dB\", psnr_epoch, step=epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch:03d} | train {train_loss_epoch:.4f} | PSNR {psnr_epoch:.2f} dB | {epoch_time:.1f}s\")\n",
    "\n",
    "        # --- checkpoint & preview on improvement ---\n",
    "        improved = (not (psnr_epoch != psnr_epoch)) and (psnr_epoch > best_psnr)\n",
    "        if improved:\n",
    "            best_psnr = psnr_epoch\n",
    "            torch.save({\"epoch\": epoch, \"state_dict\": net.state_dict()}, best_path)\n",
    "            mlflow.log_artifact(best_path, artifact_path=\"checkpoints\")\n",
    "\n",
    "            # small preview artifact\n",
    "            try:\n",
    "                # take a tiny batch from val or train\n",
    "                sample_batch = next(iter(loader_val if loader_val is not None else loader_train))\n",
    "                s = to_ch(sample_batch[0]).to(device)\n",
    "                b = to_ch(sample_batch[1]).to(device)\n",
    "                with torch.no_grad():\n",
    "                    p = net(b)\n",
    "                fig_path = _preview_triplet(b, p, s, save_path=\"preview_epoch.png\")\n",
    "                mlflow.log_artifact(fig_path, artifact_path=\"figures\")\n",
    "            except Exception as e:\n",
    "                print(\"preview logging failed:\", e)\n",
    "\n",
    "    # (optional) log the final model weights artifact one more time\n",
    "    if os.path.exists(best_path):\n",
    "        mlflow.log_artifact(best_path, artifact_path=\"checkpoints_final\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deblur3d)",
   "language": "python",
   "name": "deblur3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
