{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348e1f56-add7-41dd-8b87-1a0f1144acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "U:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- core ---\n",
    "import os, time, math\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# --- your project modules ---\n",
    "from deblur3d.losses import DeblurLoss, ssim3d\n",
    "from deblur3d.models import UNet3D_Residual\n",
    "from deblur3d.data import MultiPageTiffDataset\n",
    "from deblur3d.transforms import GaussianIsoBlurCPUTransform\n",
    "\n",
    "\n",
    "# --- mlflow ---\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")   # MLflow server URI\n",
    "mlflow.set_experiment(\"deblur3d_unet\")            # experiment name\n",
    "\n",
    "# --------- config ---------\n",
    "index_path      = r\"T:\\users\\taki\\Dataset_L\\index_with_split.xlsx\"  # or .xlsx/.csv\n",
    "patch_size      = (64, 256, 256)\n",
    "batch_size      = 8\n",
    "num_workers     = 4\n",
    "seed            = 42\n",
    "epochs          = 10\n",
    "lr              = 1e-3\n",
    "weight_decay    = 1e-4\n",
    "betas           = (0.9, 0.99)\n",
    "amp_enabled     = torch.cuda.is_available()\n",
    "save_dir        = Path(\"./checkpoints\"); save_dir.mkdir(parents=True, exist_ok=True)\n",
    "run_name        = f\"unet3d_residual_ps{patch_size}_bs{batch_size}\"\n",
    "\n",
    "# Blur transform (CPU)\n",
    "blur_tf = GaussianIsoBlurCPUTransform(\n",
    "    fwhm_range=(8, 10),\n",
    "    radius_mult=3,\n",
    "    add_noise=True,\n",
    "    poisson_gain_range=(300, 900),\n",
    "    read_noise_std_range=(0.006, 0.015),\n",
    ")\n",
    "\n",
    "# Loss\n",
    "criterion = DeblurLoss(\n",
    "    w_l1=0.7, w_ssim=0.1, w_freq=0.1, id_weight=0.1,\n",
    "    use_relative_freq=True, freq_alpha=1.0\n",
    ")\n",
    "\n",
    "assert torch.cuda.device_count() >= 2, \"Need at least 2 GPUs for DataParallel\"\n",
    "device_ids = [0, 1]          # or [0,1] explicitly\n",
    "main_device = torch.device(f\"cuda:{device_ids[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c150de6-fb98-4409-9ef7-bb00ef0d033b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vols: 418 | Val vols: 49\n"
     ]
    }
   ],
   "source": [
    "# Train / Val datasets from the index file with 'split' column\n",
    "ds_train = MultiPageTiffDataset(\n",
    "    manifest_path=index_path,\n",
    "    split=\"train\",\n",
    "    patch_size=patch_size,\n",
    "    blur_transform=blur_tf,\n",
    "    balance=None,              # or \"slice_count\"\n",
    "    samples_per_epoch=None,    # set an int to cap per-epoch samples, else len(vols)\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "ds_val = MultiPageTiffDataset(\n",
    "    manifest_path=index_path,\n",
    "    split=\"val\",\n",
    "    patch_size=patch_size,\n",
    "    blur_transform=blur_tf,    # keep or remove blur for val (often you want identity blur)\n",
    "    balance=None,\n",
    "    samples_per_epoch=None,\n",
    "    seed=seed+1,\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=min(batch_size, len(ds_train)),\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=(num_workers > 0),\n",
    ")\n",
    "\n",
    "loader_val = DataLoader(\n",
    "    ds_val,\n",
    "    batch_size=min(batch_size, len(ds_val)),\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=(num_workers > 0),\n",
    ")\n",
    "\n",
    "print(f\"Train vols: {len(ds_train)} | Val vols: {len(ds_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "231c871b-9ff6-40ee-8cd9-5eab82d5e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_single = UNet3D_Residual(in_ch=1, base=16, levels=4).to(main_device)\n",
    "net = torch.nn.DataParallel(net_single, device_ids=device_ids)\n",
    "opt = torch.optim.AdamW(net.parameters(), lr=lr, weight_decay=weight_decay, betas=betas)\n",
    "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=epochs)\n",
    "scaler = GradScaler(enabled=amp_enabled)\n",
    "\n",
    "def to_ch(x):  # (B,1,D,H,W)\n",
    "    return x.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87709af-efae-49da-8018-556d33a03ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 001 [train]:   0%|                                                                        | 0/53 [00:00<?, ?it/s]U:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\torch\\cuda\\nccl.py:15: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn(\"PyTorch is not compiled with NCCL support\")\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss 8.5018 | val_psnr 17.87 dB | val_ssim 0.0583 | time 394.2s\n",
      "  â†³ saved best: checkpoints\\deblur3d_unet_best.pt (PSNR 17.87 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | train_loss 5.6696 | val_psnr 20.62 dB | val_ssim 0.0643 | time 375.9s\n",
      "  â†³ saved best: checkpoints\\deblur3d_unet_best.pt (PSNR 20.62 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | train_loss 5.0814 | val_psnr 20.91 dB | val_ssim 0.0620 | time 376.0s\n",
      "  â†³ saved best: checkpoints\\deblur3d_unet_best.pt (PSNR 20.91 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | train_loss 5.1331 | val_psnr 21.04 dB | val_ssim 0.0585 | time 378.9s\n",
      "  â†³ saved best: checkpoints\\deblur3d_unet_best.pt (PSNR 21.04 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss 4.9250 | val_psnr 20.97 dB | val_ssim 0.0676 | time 372.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | train_loss 4.8192 | val_psnr 21.12 dB | val_ssim 0.0648 | time 370.5s\n",
      "  â†³ saved best: checkpoints\\deblur3d_unet_best.pt (PSNR 21.12 dB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run unet3d_residual_ps(64, 256, 256)_bs8 at: http://127.0.0.1:5000/#/experiments/168148162419857529/runs/93e3e9b1084149ad82846cd0453ab272\n",
      "ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/168148162419857529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m train_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(loader_train, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [train]\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sharp, blurred \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[0;32m     27\u001b[0m     sharp   \u001b[38;5;241m=\u001b[39m to_ch(sharp)\u001b[38;5;241m.\u001b[39mto(main_device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m     blurred \u001b[38;5;241m=\u001b[39m to_ch(blurred)\u001b[38;5;241m.\u001b[39mto(main_device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:436\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator()\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 436\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1112\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._reset\u001b[1;34m(self, loader, first_iter)\u001b[0m\n\u001b[0;32m   1110\u001b[0m resume_iteration_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_workers\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m resume_iteration_cnt \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1112\u001b[0m     return_idx, return_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(return_idx, _utils\u001b[38;5;241m.\u001b[39mworker\u001b[38;5;241m.\u001b[39m_ResumeIteration):\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m return_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mU:\\users\\taki\\Anaconda\\envs\\deblur3d\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_psnr = -1.0\n",
    "best_path = save_dir / \"deblur3d_unet_best.pt\"\n",
    "\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"UNet3D_Residual\",\n",
    "        \"patch_size\": str(patch_size),\n",
    "        \"batch_size\": batch_size,\n",
    "        \"num_workers\": num_workers,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \"betas\": str(betas),\n",
    "        \"epochs\": epochs,\n",
    "        \"amp\": amp_enabled,\n",
    "        \"index_path\": index_path,\n",
    "    })\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0 = time.perf_counter()\n",
    "        net.train()\n",
    "        train_loss_sum = 0.0\n",
    "        train_count = 0\n",
    "\n",
    "        pbar = tqdm(loader_train, desc=f\"Epoch {epoch:03d} [train]\", leave=False)\n",
    "        for sharp, blurred in pbar:\n",
    "            sharp   = to_ch(sharp).to(main_device, non_blocking=True)\n",
    "            blurred = to_ch(blurred).to(main_device, non_blocking=True)\n",
    "\n",
    "            with autocast(enabled=amp_enabled):\n",
    "                pred = net(blurred)\n",
    "                loss = criterion(pred, sharp, blurred)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(opt)\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            bsz = sharp.size(0)\n",
    "            train_loss_sum += loss.item() * bsz\n",
    "            train_count += bsz\n",
    "\n",
    "            # live progress\n",
    "            pbar.set_postfix(\n",
    "                loss=f\"{train_loss_sum/max(train_count,1):.4f}\",\n",
    "                lr=f\"{sched.get_last_lr()[0]:.2e}\"\n",
    "            )\n",
    "\n",
    "        sched.step()\n",
    "        train_loss = train_loss_sum / max(train_count, 1)\n",
    "\n",
    "        # ---- validation ----\n",
    "        net.eval()\n",
    "        psnr_sum = 0.0\n",
    "        ssim_sum = 0.0\n",
    "        val_count = 0\n",
    "\n",
    "        pbar_val = tqdm(loader_val, desc=f\"Epoch {epoch:03d} [val]  \", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for sharp, blurred in pbar_val:\n",
    "                sharp   = to_ch(sharp).to(main_device, non_blocking=True)\n",
    "                blurred = to_ch(blurred).to(main_device, non_blocking=True)\n",
    "                with autocast(enabled=amp_enabled):\n",
    "                    pred = net(blurred)\n",
    "                    mse  = F.mse_loss(pred, sharp, reduction='none').mean(dim=(1,2,3,4))\n",
    "                    psnr = 10 * torch.log10(1.0 / (mse + 1e-12))\n",
    "                    ssim_vals = ssim3d(pred, sharp).detach()\n",
    "\n",
    "                psnr_sum += psnr.sum().item()\n",
    "                ssim_sum += ssim_vals.sum().item()\n",
    "                val_count += sharp.size(0)\n",
    "\n",
    "                # live progress\n",
    "                cur_psnr = psnr.mean().item()\n",
    "                cur_ssim = ssim_vals.mean().item()\n",
    "                pbar_val.set_postfix(psnr=f\"{cur_psnr:.2f}\", ssim=f\"{cur_ssim:.3f}\")\n",
    "\n",
    "        val_psnr = psnr_sum / max(val_count, 1)\n",
    "        val_ssim = ssim_sum / max(val_count, 1)\n",
    "        epoch_time = time.perf_counter() - t0\n",
    "\n",
    "        # console summary line\n",
    "        print(f\"Epoch {epoch:03d} | train_loss {train_loss:.4f} | \"\n",
    "              f\"val_psnr {val_psnr:.2f} dB | val_ssim {val_ssim:.4f} | \"\n",
    "              f\"time {epoch_time:.1f}s\")\n",
    "\n",
    "        # MLflow\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_psnr\": val_psnr,\n",
    "            \"val_ssim\": val_ssim,\n",
    "            \"epoch_time_s\": epoch_time,\n",
    "            \"lr\": sched.get_last_lr()[0],\n",
    "        }, step=epoch)\n",
    "\n",
    "        # save best\n",
    "        is_best = val_psnr > best_psnr\n",
    "        if is_best:\n",
    "            best_psnr = val_psnr\n",
    "            torch.save({\"epoch\": epoch, \"state_dict\": getattr(net, \"module\", net).state_dict()}, best_path)\n",
    "            mlflow.log_artifact(str(best_path))\n",
    "            mlflow.log_metric(\"best_val_psnr\", best_psnr, step=epoch)\n",
    "            print(f\"  â†³ saved best: {best_path} (PSNR {best_psnr:.2f} dB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd2005f-7ebe-4b6c-9ff0-3a3255505310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc7266-0f00-45b2-a77c-61746e5397e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deblur3d)",
   "language": "python",
   "name": "deblur3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
